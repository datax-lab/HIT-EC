{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1086cc7f-32ea-410f-b08a-f0909f03467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.model import Model\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30121f0-778e-4aa8-9ee3-49f4581f889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./utils/tokenizer.pickle', 'rb') as f :\n",
    "    tokenizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb992bb6-30f5-417c-be43-ee2766da5139",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f'./utils/model.ckpt'\n",
    "\n",
    "config = {\n",
    "    'ah': 2,\n",
    "    'dr': 0.1,\n",
    "    'beta': 0.59,\n",
    "    'output_dims': [7, 72, 268, 4255]\n",
    "}\n",
    "\n",
    "model = Model(config)\n",
    "\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu'))['state_dict'])\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa0a566-e223-4c81-877d-b29c53b4c9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = 'AAAAA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ea5a7a-15c5-4765-b9b5-8c2df45ebea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = tokenizer.texts_to_sequences([sequence])\n",
    "sequence[0] = [22] + sequence[0]\n",
    "sequence[0] += [0 for _ in range(1024-len(sequence[0]))]\n",
    "sequence = torch.Tensor(sequence).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3bb12d-36e3-48be-8b49-c3e971007944",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(sequence, mode='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f11530-0f2f-4563-a203-ab1ad00f1079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_heads(cam, grad):\n",
    "    cam = cam.reshape(-1, cam.shape[-2], cam.shape[-1])\n",
    "    grad = grad.reshape(-1, grad.shape[-2], grad.shape[-1])\n",
    "    cam = grad * cam\n",
    "    cam = cam.clamp(min=0).mean(dim=0)\n",
    "    return cam\n",
    "\n",
    "def apply_self_attention_rules(R_ss, cam_ss):\n",
    "    R_ss_addition = torch.matmul(cam_ss, R_ss)\n",
    "    return R_ss_addition\n",
    "\n",
    "def generate_relevance(sequence, model, level_sizes=[7,72,268,4255], labels=None, target_ec=None, force_chain=True, max_len=1024, bos_id=22):\n",
    "    seq = tokenizer.texts_to_sequences([sequence])\n",
    "    seq[0] = [bos_id] + seq[0]\n",
    "    seq[0] += [0 for _ in range(max_len - len(seq[0]))]\n",
    "    device = next(model.parameters()).device if any(True for _ in model.parameters()) else torch.device(\"cpu\")\n",
    "    seq = torch.tensor(seq, dtype=torch.int32, device=device)\n",
    "\n",
    "    starts = [0]\n",
    "    for s in level_sizes[:-1]:\n",
    "        starts.append(starts[-1] + s)\n",
    "\n",
    "    def rollout(global_idx):\n",
    "        model.eval()\n",
    "        out_inter = model(seq, mode='inter')\n",
    "        one_hot = torch.zeros((1, out_inter.size(-1)), dtype=torch.float32, device=out_inter.device)\n",
    "        one_hot[0, global_idx] = 100.0\n",
    "        t = torch.sum(one_hot * out_inter)\n",
    "        model.zero_grad()\n",
    "        t.backward()\n",
    "        R = torch.eye(max_len, max_len, device=out_inter.device)\n",
    "        for blk in [model.model.enc_1, model.model.enc_2, model.model.enc_3, model.model.enc_4]:\n",
    "            cam = blk.inter_attention.get_attn()\n",
    "            grad = blk.inter_attention.get_attn_gradients()\n",
    "            cam = avg_heads(cam, grad)\n",
    "            R = R + apply_self_attention_rules(R, cam)\n",
    "        return R[0,1:]\n",
    "\n",
    "    def global_from_level(i_level, local_idx):\n",
    "        return starts[i_level] + local_idx\n",
    "\n",
    "    if target_ec is not None:\n",
    "        if labels is None:\n",
    "            raise ValueError(\"labels (per-level or flat) required to locate target_ec\")\n",
    "        if force_chain and isinstance(labels[0], (list, tuple)):\n",
    "            parts = str(target_ec).split(\".\")\n",
    "            chain = []\n",
    "            if len(parts) >= 1: chain.append(parts[0])\n",
    "            if len(parts) >= 2: chain.append(\".\".join(parts[:2]))\n",
    "            if len(parts) >= 3: chain.append(\".\".join(parts[:3]))\n",
    "            if len(parts) >= 4: chain.append(\".\".join(parts[:4]))\n",
    "            targets = []\n",
    "            for i, ec_str in enumerate(chain):\n",
    "                try:\n",
    "                    li = labels[i].index(ec_str)\n",
    "                    gi = global_from_level(i, li)\n",
    "                    targets.append(gi)\n",
    "                    print(f\"Forced L{i+1}: {ec_str} | gidx={gi}\")\n",
    "                except ValueError:\n",
    "                    print(f\"Forced L{i+1}: {ec_str} not found, skipping\")\n",
    "            if not targets:\n",
    "                raise ValueError(\"No levels found for target_ec in labels\")\n",
    "            Rs = [rollout(gi) for gi in targets]\n",
    "            return torch.stack(Rs, dim=0).mean(dim=0)\n",
    "        else:\n",
    "            if isinstance(labels[0], (list, tuple)):\n",
    "                off = 0\n",
    "                gi = None\n",
    "                for i, lab in enumerate(labels):\n",
    "                    try:\n",
    "                        li = lab.index(target_ec)\n",
    "                        gi = off + li\n",
    "                        break\n",
    "                    except ValueError:\n",
    "                        off += level_sizes[i]\n",
    "                if gi is None:\n",
    "                    raise ValueError(\"target_ec not found in labels\")\n",
    "            else:\n",
    "                try:\n",
    "                    gi = int(labels.index(target_ec))\n",
    "                except ValueError:\n",
    "                    raise ValueError(\"target_ec not found in labels\")\n",
    "            print(f\"Forced EC: {target_ec} | gidx={gi}\")\n",
    "            return rollout(gi)\n",
    "\n",
    "    model.eval()\n",
    "    out_infer = model(seq, mode='infer')\n",
    "    Rs = []\n",
    "    for i in range(4):\n",
    "        s, e = starts[i], starts[i] + level_sizes[i]\n",
    "        logits = out_infer[0, s:e]\n",
    "        li = int(torch.argmax(logits).item())\n",
    "        gi = s + li\n",
    "        sc = float(torch.max(logits).item())\n",
    "        if labels is not None:\n",
    "            try:\n",
    "                lbl = labels[i][li] if isinstance(labels[0], (list,tuple)) else labels[gi]\n",
    "            except Exception:\n",
    "                lbl = f\"idx{li}\"\n",
    "            print(f\"L{i+1}: {lbl} | score={sc:.6f} | gidx={gi}\")\n",
    "        else:\n",
    "            print(f\"L{i+1}: idx={li} | score={sc:.6f} | gidx={gi}\")\n",
    "        Rs.append(rollout(gi))\n",
    "        \n",
    "    thresh=0.4\n",
    "    s4, e4 = starts[3], starts[3] + level_sizes[3]\n",
    "    logits_l4 = out_infer[0, s4:e4]\n",
    "    probs_l4 = torch.sigmoid(logits_l4)  \n",
    "    idxs = (probs_l4 > thresh).nonzero(as_tuple=False).flatten().tolist()\n",
    "    if idxs:\n",
    "        cands = sorted(((li, float(probs_l4[li].item())) for li in idxs), key=lambda x: -x[1])\n",
    "        print(f\"--- L4 candidates with score > {thresh} ---\")\n",
    "        for li, sc in cands:\n",
    "            gi = s4 + li\n",
    "            if labels is not None:\n",
    "                try:\n",
    "                    lbl = labels[3][li] if isinstance(labels[0], (list, tuple)) else labels[gi]\n",
    "                except Exception:\n",
    "                    lbl = f\"idx{li}\"\n",
    "            else:\n",
    "                lbl = f\"idx{li}\"\n",
    "            print(f\"L4 candidate: {lbl} | score={sc:.6f} | gidx={gi}\")\n",
    "            \n",
    "    return torch.stack(Rs, dim=0).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e62e08b-cf09-44f2-b5fc-abf2cf7f2bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = 'AAA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0645781a-3059-4ca1-84e0-24cbc2b84532",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = generate_relevance(sequence, model).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4b13dd-f89b-477c-88da-2ac9a9aa8b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 6\n",
    "kernel = np.ones(kernel_size) / kernel_size\n",
    "exp = np.convolve(exp, kernel, mode='same')\n",
    "\n",
    "exp = exp - exp.min()\n",
    "exp = exp / exp.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f48e01f-1156-4d40-940e-abb5981e313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f629b2-bc82-4079-9f73-73de04530b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_alpha(value, text, color):\n",
    "    img = plot(value, color)\n",
    "    img = np.asarray(img, dtype=np.uint8)\n",
    "    pil_img = Image.fromarray(img)\n",
    "    draw = ImageDraw.Draw(pil_img)\n",
    "\n",
    "    margin = 0\n",
    "    for size in range(30, 5, -1):\n",
    "        try:\n",
    "            font = ImageFont.truetype(\"DejaVuSans.ttf\", size=size)\n",
    "        except:\n",
    "            font = ImageFont.load_default()\n",
    "        bbox = draw.textbbox((0, 0), str(text), font=font)\n",
    "        w = bbox[2] - bbox[0]\n",
    "        h = font.getmetrics()[0] + font.getmetrics()[1]\n",
    "        if w <= pil_img.width - margin and h <= pil_img.height - margin:\n",
    "            break\n",
    "\n",
    "    ascent, descent = font.getmetrics()\n",
    "    text_h = ascent + descent\n",
    "    x = (pil_img.width - w) // 2\n",
    "    y = (pil_img.height - text_h) // 2 + ascent//10\n",
    "\n",
    "    draw.text((x, y), str(text), fill=(10, 10, 10), font=font)\n",
    "    return np.array(pil_img, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81d97f1-8f56-4650-a886-86298cb7f77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "r_img = np.zeros((30, 30 * len(sequence), 3), dtype=np.uint8)\n",
    "\n",
    "cmap = plt.get_cmap('Reds')\n",
    "norm = mcolors.Normalize(vmin=min(exp), vmax=max(exp))\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "\n",
    "for e in range(len(sequence)):\n",
    "    r, g, b, a = sm.to_rgba(np.array(exp)[e])\n",
    "    color = np.array([r, g, b]) * 255\n",
    "    img = plotting_alpha(np.array(exp)[e], sequence[e], color)\n",
    "    r_img[:, e * 30:(e + 1) * 30] = img\n",
    "\n",
    "Image.fromarray(r_img).save(\"interpretation.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvlouis",
   "language": "python",
   "name": "venvlouis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
