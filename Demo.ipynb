{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1086cc7f-32ea-410f-b08a-f0909f03467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Model\n",
    "from inter_model import InterpretationModel\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30121f0-778e-4aa8-9ee3-49f4581f889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./tokenizer.pickle', 'rb') as f :\n",
    "    tokenizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb992bb6-30f5-417c-be43-ee2766da5139",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f'./model.ckpt'\n",
    "\n",
    "config = {\n",
    "    'ah': 2,\n",
    "    'dr': 0.1,\n",
    "    'beta': 0.59,\n",
    "    'output_dims': [7, 72, 268, 4255]\n",
    "}\n",
    "\n",
    "model = Model(config)\n",
    "\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu'))['callbacks']['StochasticWeightAveraging']['average_model_state'])\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa0a566-e223-4c81-877d-b29c53b4c9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = 'AAAAA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ea5a7a-15c5-4765-b9b5-8c2df45ebea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = tokenizer.texts_to_sequences([sequence])\n",
    "sequence[0] = [22] + sequence[0]\n",
    "sequence[0] += [0 for _ in range(1024-len(sequence[0]))]\n",
    "sequence = torch.Tensor(sequence).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3bb12d-36e3-48be-8b49-c3e971007944",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ff668f-0cd4-4e55-a4d0-b34d2368d664",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f'./inter_model.ckpt'\n",
    "\n",
    "config = {\n",
    "    'ah': 2,\n",
    "    'dr': 0.1,\n",
    "    'beta': 0.59,\n",
    "    'output_dims': [7, 72, 268, 4255]\n",
    "}\n",
    "\n",
    "model = InterpretationModel(config)\n",
    "\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu'))['state_dict'])\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe910a7-428d-4c1c-909a-43fd67ebd69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_heads(cam, grad):\n",
    "    cam = cam.reshape(-1, cam.shape[-2], cam.shape[-1])\n",
    "    grad = grad.reshape(-1, grad.shape[-2], grad.shape[-1])\n",
    "    cam = grad * cam\n",
    "    cam = cam.clamp(min=0).mean(dim=0)\n",
    "    return cam\n",
    "\n",
    "def apply_self_attention_rules(R_ss, cam_ss):\n",
    "    R_ss_addition = torch.matmul(cam_ss, R_ss)\n",
    "    return R_ss_addition\n",
    "\n",
    "def generate_relevance(model, sequence, index=None):\n",
    "    \n",
    "    sequence = tokenizer.texts_to_sequences([sequence])\n",
    "    sequence[0] = [22] + sequence[0]\n",
    "    sequence[0] += [0 for _ in range(1024-len(sequence[0]))]\n",
    "    sequence = torch.Tensor(sequence).int()\n",
    "\n",
    "    output = model(sequence)\n",
    "    if index == None:\n",
    "        index = np.argmax(output.cpu().data.numpy(), axis=-1)\n",
    "\n",
    "    one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)\n",
    "    one_hot[0, index] = 1\n",
    "    one_hot_vector = one_hot\n",
    "    one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
    "    one_hot = torch.sum(one_hot * output)\n",
    "    model.zero_grad()\n",
    "    one_hot.backward(retain_graph=True)\n",
    "\n",
    "    num_tokens = 1024\n",
    "    R = torch.eye(num_tokens, num_tokens)\n",
    "    for blk in [model.model.enc_1, model.model.enc_2, model.model.enc_3, model.model.enc_4]:\n",
    "        grad = blk.attention.get_attn_gradients()\n",
    "        cam = blk.attention.get_attn()\n",
    "        cam = avg_heads(cam, grad)\n",
    "        R += apply_self_attention_rules(R, cam)\n",
    "    return R[0, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e62e08b-cf09-44f2-b5fc-abf2cf7f2bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = 'AAA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0645781a-3059-4ca1-84e0-24cbc2b84532",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = generate_relevance(model, sequence, index=None).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4b13dd-f89b-477c-88da-2ac9a9aa8b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 6\n",
    "kernel = np.ones(kernel_size) / kernel_size\n",
    "exp = np.convolve(exp, kernel, mode='same')\n",
    "\n",
    "exp = exp - exp.min()\n",
    "exp = exp / exp.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f48e01f-1156-4d40-940e-abb5981e313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffdaf51-925c-4bfa-9f49-87ad4179d185",
   "metadata": {},
   "source": [
    "## Test with New-392"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb357315-3de5-4b01-83bb-14aebae971a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f'./model.ckpt'\n",
    "\n",
    "config = {\n",
    "    'ah': 2,\n",
    "    'dr': 0.1,\n",
    "    'beta': 0.59,\n",
    "    'output_dims': [7, 72, 268, 4255]\n",
    "}\n",
    "\n",
    "model = Model(config)\n",
    "\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu'))['callbacks']['StochasticWeightAveraging']['average_model_state'])\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6ff185-597d-4e74-a1b0-f62e028db179",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./label_encoder.pkl', 'rb') as f :\n",
    "    le = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca9ec6f-77db-4ca9-aa84-e037a24fc217",
   "metadata": {},
   "outputs": [],
   "source": [
    "new392 = pd.read_csv('./new.csv', sep='\\t')\n",
    "\n",
    "labels = [] \n",
    "preds = [] \n",
    "\n",
    "ec_number_pattern = r'\\b\\d+\\.\\d+\\.\\d+\\.\\d+\\b'\n",
    "    \n",
    "with torch.no_grad() :\n",
    "    for index, row in tqdm(new392.iterrows(), total=len(new392)) : \n",
    "\n",
    "        sequence = row['Sequence']\n",
    "        sequence = tokenizer.texts_to_sequences([sequence[:1023]])\n",
    "        sequence[0] = [22] + sequence[0]\n",
    "        sequence[0] += [0 for _ in range(1024-len(sequence[0]))]\n",
    "        sequence = torch.Tensor(sequence).int()\n",
    "\n",
    "        output = (model(sequence)[:, -4255:] > 0.4).int()[0]\n",
    "\n",
    "        label = row['EC number'].split(';')\n",
    "        matches = re.findall(ec_number_pattern, ','.join(label))\n",
    "\n",
    "        labels.append([1 if ec in label else 0 for ec in le.classes_])\n",
    "        preds.append(output.tolist())\n",
    "\n",
    "\n",
    "print(f\"Micro-averaged F1-score: {sklearn.metrics.f1_score(labels, preds, average='micro'):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvlouis",
   "language": "python",
   "name": "venvlouis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
