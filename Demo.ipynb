{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1086cc7f-32ea-410f-b08a-f0909f03467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Model\n",
    "from inter_model import InterpretationModel\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f30121f0-778e-4aa8-9ee3-49f4581f889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./tokenizer.pickle', 'rb') as f :\n",
    "    tokenizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb992bb6-30f5-417c-be43-ee2766da5139",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f'./model.ckpt'\n",
    "\n",
    "config = {\n",
    "    'ah': 2,\n",
    "    'dr': 0.1,\n",
    "    'beta': 0.59,\n",
    "    'output_dims': [7, 72, 268, 4255]\n",
    "}\n",
    "\n",
    "model = Model(config)\n",
    "\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu'))['callbacks']['StochasticWeightAveraging']['average_model_state'])\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfa0a566-e223-4c81-877d-b29c53b4c9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = 'AAAAA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6ea5a7a-15c5-4765-b9b5-8c2df45ebea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = tokenizer.texts_to_sequences([sequence])\n",
    "sequence[0] = [22] + sequence[0]\n",
    "sequence[0] += [0 for _ in range(1024-len(sequence[0]))]\n",
    "sequence = torch.Tensor(sequence).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a3bb12d-36e3-48be-8b49-c3e971007944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.8450e-01, 5.8693e-03, 1.6082e-01,  ..., 1.5032e-09, 1.4772e-09,\n",
       "         3.3178e-10]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05ff668f-0cd4-4e55-a4d0-b34d2368d664",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f'./inter_model.ckpt'\n",
    "\n",
    "config = {\n",
    "    'ah': 2,\n",
    "    'dr': 0.1,\n",
    "    'beta': 0.59,\n",
    "    'output_dims': [7, 72, 268, 4255]\n",
    "}\n",
    "\n",
    "model = InterpretationModel(config)\n",
    "\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu'))['state_dict'])\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5fe910a7-428d-4c1c-909a-43fd67ebd69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_heads(cam, grad):\n",
    "    cam = cam.reshape(-1, cam.shape[-2], cam.shape[-1])\n",
    "    grad = grad.reshape(-1, grad.shape[-2], grad.shape[-1])\n",
    "    cam = grad * cam\n",
    "    cam = cam.clamp(min=0).mean(dim=0)\n",
    "    return cam\n",
    "\n",
    "# rule 6 from paper\n",
    "def apply_self_attention_rules(R_ss, cam_ss):\n",
    "    R_ss_addition = torch.matmul(cam_ss, R_ss)\n",
    "    return R_ss_addition\n",
    "\n",
    "def generate_relevance(model, sequence, index=None):\n",
    "    \n",
    "    sequence = tokenizer.texts_to_sequences([sequence])\n",
    "    sequence[0] = [22] + sequence[0]\n",
    "    sequence[0] += [0 for _ in range(1024-len(sequence[0]))]\n",
    "    sequence = torch.Tensor(sequence).int()\n",
    "\n",
    "    output = model(sequence)\n",
    "    if index == None:\n",
    "        index = np.argmax(output.cpu().data.numpy(), axis=-1)\n",
    "\n",
    "    one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)\n",
    "    one_hot[0, index] = 1\n",
    "    one_hot_vector = one_hot\n",
    "    one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
    "    one_hot = torch.sum(one_hot * output)\n",
    "    model.zero_grad()\n",
    "    one_hot.backward(retain_graph=True)\n",
    "\n",
    "    num_tokens = 1024\n",
    "    R = torch.eye(num_tokens, num_tokens)\n",
    "    for blk in [model.model.enc_1, model.model.enc_2, model.model.enc_3, model.model.enc_4]:\n",
    "        grad = blk.attention.get_attn_gradients()\n",
    "        cam = blk.attention.get_attn()\n",
    "        cam = avg_heads(cam, grad)\n",
    "        R += apply_self_attention_rules(R, cam)\n",
    "    return R[0, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e62e08b-cf09-44f2-b5fc-abf2cf7f2bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = 'AAA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0645781a-3059-4ca1-84e0-24cbc2b84532",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = generate_relevance(model, sequence, index=None).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd4b13dd-f89b-477c-88da-2ac9a9aa8b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 6\n",
    "kernel = np.ones(kernel_size) / kernel_size\n",
    "exp = np.convolve(exp, kernel, mode='same')\n",
    "\n",
    "exp = exp - exp.min()\n",
    "exp = exp / exp.max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvlouis",
   "language": "python",
   "name": "venvlouis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
